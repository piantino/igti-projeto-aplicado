{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Scikit-Learn To Classify Your Own Text Data (The Short Version)\n",
    "\n",
    "http://carrefax.com/articles-blog/2018/3/11/using-scikit-learn-to-classify-your-own-text-data-the-short-version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "colunas = ['ROTULO_MANUAL', 'EMENTA_NORM']\n",
    "\n",
    "df = pd.read_csv('../../data/ementas_pre-processadas.csv', header=0, sep=',', quotechar='\"', usecols=colunas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df['EMENTA_NORM'].values.astype('U')\n",
    "target = df['ROTULO_MANUAL']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the training data into tfidf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transforming the training data...\n",
      "\n",
      "(4870, 16316)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<0x16316 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "print ('\\nTransforming the training data...\\n')\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(raw_documents=X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(use_idf=False)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print (X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the test data into tfidf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transforming the test data...\n",
      "\n",
      "(3247, 14414)\n",
      "  (0, 4400)\t0.045407660918649985\n",
      "  (0, 2956)\t0.045407660918649985\n",
      "  (0, 11729)\t0.045407660918649985\n",
      "  (0, 8873)\t0.045407660918649985\n",
      "  (0, 9382)\t0.045407660918649985\n",
      "  (0, 1266)\t0.045407660918649985\n",
      "  (0, 6806)\t0.045407660918649985\n",
      "  (0, 8391)\t0.045407660918649985\n",
      "  (0, 1775)\t0.045407660918649985\n",
      "  (0, 990)\t0.045407660918649985\n",
      "  (0, 14113)\t0.045407660918649985\n",
      "  (0, 5937)\t0.045407660918649985\n",
      "  (0, 10529)\t0.045407660918649985\n",
      "  (0, 13348)\t0.045407660918649985\n",
      "  (0, 1911)\t0.045407660918649985\n",
      "  (0, 11047)\t0.045407660918649985\n",
      "  (0, 10845)\t0.045407660918649985\n",
      "  (0, 10822)\t0.045407660918649985\n",
      "  (0, 11727)\t0.045407660918649985\n",
      "  (0, 6971)\t0.045407660918649985\n",
      "  (0, 12636)\t0.045407660918649985\n",
      "  (0, 6293)\t0.045407660918649985\n",
      "  (0, 8749)\t0.045407660918649985\n",
      "  (0, 13059)\t0.045407660918649985\n",
      "  (0, 12256)\t0.045407660918649985\n",
      "  :\t:\n",
      "  (3246, 14009)\t0.11704114719613057\n",
      "  (3246, 5109)\t0.11704114719613057\n",
      "  (3246, 2037)\t0.11704114719613057\n",
      "  (3246, 8839)\t0.11704114719613057\n",
      "  (3246, 8485)\t0.11704114719613057\n",
      "  (3246, 4757)\t0.11704114719613057\n",
      "  (3246, 13609)\t0.11704114719613057\n",
      "  (3246, 4350)\t0.11704114719613057\n",
      "  (3246, 3522)\t0.3511234415883917\n",
      "  (3246, 5882)\t0.11704114719613057\n",
      "  (3246, 7653)\t0.11704114719613057\n",
      "  (3246, 10805)\t0.11704114719613057\n",
      "  (3246, 176)\t0.11704114719613057\n",
      "  (3246, 9791)\t0.11704114719613057\n",
      "  (3246, 11753)\t0.11704114719613057\n",
      "  (3246, 3773)\t0.11704114719613057\n",
      "  (3246, 3784)\t0.11704114719613057\n",
      "  (3246, 5124)\t0.11704114719613057\n",
      "  (3246, 11729)\t0.11704114719613057\n",
      "  (3246, 1266)\t0.3511234415883917\n",
      "  (3246, 9533)\t0.11704114719613057\n",
      "  (3246, 10007)\t0.11704114719613057\n",
      "  (3246, 12803)\t0.11704114719613057\n",
      "  (3246, 2341)\t0.11704114719613057\n",
      "  (3246, 983)\t0.11704114719613057\n",
      "(4870,)\n"
     ]
    }
   ],
   "source": [
    "print ('\\nTransforming the test data...\\n')\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_test_counts = count_vect.fit_transform(raw_documents=X_test)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(use_idf=False)\n",
    "X_test_tfidf = tfidf_transformer.fit_transform(X_test_counts)\n",
    "print (X_test_tfidf.shape)\n",
    "\n",
    "print (X_test_tfidf)\n",
    "print (y_train.shape)\n",
    "\n",
    "docs_test = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the classifier pipeline using a SGDClassifier algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying the classifier...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "print ('\\nApplying the classifier...\\n')\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    #('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, verbose=1)),\n",
    "    ('clf', LinearSVC(random_state=0, tol=1e-5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=1e-05, verbose=0))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the test data into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(docs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate mean accuracy of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.745611333538651\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print (np.mean(predicted == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate labelled performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        AUT       1.00      0.56      0.72        16\n",
      "        BAN       0.68      0.73      0.71       341\n",
      "        BUS       0.72      0.65      0.69        89\n",
      "        CDC       0.71      0.49      0.58        70\n",
      "        CIV       0.60      0.25      0.35        12\n",
      "        COM       0.45      0.11      0.18        44\n",
      "        CON       0.59      0.63      0.61       259\n",
      "        DAN       0.60      0.74      0.66       294\n",
      "        DMI       0.68      0.53      0.60        95\n",
      "        DPV       0.91      0.71      0.80        45\n",
      "        EXP       0.87      0.97      0.92       561\n",
      "        FAL       0.95      0.70      0.81        30\n",
      "        FAM       0.77      0.63      0.69        79\n",
      "        INF       1.00      0.86      0.92         7\n",
      "        MAR       0.60      0.80      0.69        15\n",
      "        OIE       0.76      0.82      0.79       223\n",
      "        OIG       0.91      0.84      0.87       270\n",
      "        POS       0.81      0.68      0.74        63\n",
      "        PRE       0.95      0.69      0.80        51\n",
      "        RAI       0.65      0.61      0.63       188\n",
      "      RESCI       0.60      0.75      0.67         4\n",
      "      RESCO       1.00      0.55      0.71        11\n",
      "        SEG       0.78      0.88      0.82       281\n",
      "        SFH       0.78      0.71      0.74        65\n",
      "        SOC       1.00      0.31      0.47        13\n",
      "        SUC       0.17      0.10      0.12        10\n",
      "        TIT       0.64      0.52      0.58       111\n",
      "\n",
      "avg / total       0.75      0.75      0.74      3247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
